{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../topic_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import json, os\n",
    "\n",
    "with open('../topic_model/data/doc_vecs.json') as f:\n",
    "    doc_strs =  f.read().split('\\n')\n",
    "    docs = []\n",
    "    for idx, doc_str in enumerate(doc_strs):\n",
    "#         if idx == 200:\n",
    "#             break \n",
    "        if doc_str:\n",
    "            doc = json.loads(doc_str)\n",
    "            docs.append(doc['paragraphs'])\n",
    "\n",
    "vocab_fp = os.path.join('../topic_model/data/', 'vocab.txt')\n",
    "vocab = open(vocab_fp).read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sampler_cy\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = sampler_cy.BOW_Paragraph_GibbsSampler(docs=docs[:20000], vocab=vocab)\n",
    "s2.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.sample_pass()\n",
    "s2.pythonize_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.par_doc_to_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8856, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.switching_variable_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cProfile.run('s2.sample_pass()', 'restats')\n",
    "p = pstats.Stats('restats')\n",
    "p.strip_dirs().sort_stats(2).print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cython testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_5dfd9b17a8f4f447adf7aa2f93323e65.pyx:11:26: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_5dfd9b17a8f4f447adf7aa2f93323e65.pyx:14:18: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_5dfd9b17a8f4f447adf7aa2f93323e65.pyx:16:16: Use boundscheck(False) for faster access\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "from libc.stdlib cimport rand, RAND_MAX\n",
    "import numpy as np \n",
    "\n",
    "cdef double random_double(double max_num) nogil:\n",
    "    return (rand() / (RAND_MAX + 1) * max_num)\n",
    "\n",
    "cdef int categorical(int k, double[:] p) nogil:\n",
    "    cdef double sum_of_weight = 0;\n",
    "    cdef int i\n",
    "    for i in range(k):\n",
    "        sum_of_weight += p[i];\n",
    "    cdef double rnd = random_double(sum_of_weight);\n",
    "    for i in range(k):\n",
    "        if rnd < p[i]:\n",
    "            return i;\n",
    "        rnd -= p[i];\n",
    "        \n",
    "def init():\n",
    "    cdef double[:] partype_prob_vec = np.ones(10, dtype=np.float64)\n",
    "    cdef int partype = categorical(10, p=partype_prob_vec)\n",
    "    return partype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(100000):\n",
    "    t.append(init())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    10207\n",
       "8    10179\n",
       "4    10106\n",
       "1    10074\n",
       "9    10029\n",
       "3     9990\n",
       "0     9950\n",
       "5     9944\n",
       "7     9762\n",
       "2     9759\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(t).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cdef int a = 0\n",
    "for i in range(10):\n",
    "    a += i\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "\n",
    "from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free\n",
    "\n",
    "cdef class SomeMemory:\n",
    "    cdef double* data\n",
    "    def __cinit__(self, size_t number):\n",
    "        # allocate some memory (uninitialised, may contain arbitrary data)\n",
    "        self.data = <double*> PyMem_Malloc(number * sizeof(double))\n",
    "        if not self.data:\n",
    "            raise MemoryError()\n",
    "\n",
    "    def resize(self, size_t new_number):\n",
    "        # Allocates new_number * sizeof(double) bytes,\n",
    "        # preserving the current content and making a best-effort to\n",
    "        # re-use the original data location.\n",
    "        mem = <double*> PyMem_Realloc(self.data, new_number * sizeof(double))\n",
    "        if not mem:\n",
    "            raise MemoryError()\n",
    "        # Only overwrite the pointer if the memory was really reallocated.\n",
    "        # On error (mem is NULL), the originally memory has not been freed.\n",
    "        self.data = mem\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data[0]\n",
    "\n",
    "    def __dealloc__(self):\n",
    "        PyMem_Free(self.data)  # no-op if self.data is NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SomeMemory(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3591251795914e-311"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "DTYPE = np.intc\n",
    "\n",
    "cdef int clip(int a, int min_value, int max_value):\n",
    "    return min(max(a, min_value), max_value)\n",
    "\n",
    "def compute(int[:, :] array_1, int[:, :] array_2, int a, int b, int c):\n",
    "\n",
    "    cdef Py_ssize_t x_max = array_1.shape[0]\n",
    "    cdef Py_ssize_t y_max = array_1.shape[1]\n",
    "\n",
    "    # array_1.shape is now a C array, no it's not possible\n",
    "    # to compare it simply by using == without a for-loop.\n",
    "    # To be able to compare it to array_2.shape easily,\n",
    "    # we convert them both to Python tuples.\n",
    "    assert tuple(array_1.shape) == tuple(array_2.shape)\n",
    "\n",
    "    result = np.zeros((x_max, y_max), dtype=DTYPE)\n",
    "    cdef int[:, :] result_view = result\n",
    "\n",
    "    cdef int tmp\n",
    "    cdef Py_ssize_t x, y\n",
    "\n",
    "    for x in range(x_max):\n",
    "        for y in range(y_max):\n",
    "\n",
    "            tmp = clip(array_1[x, y], 2, 10)\n",
    "            tmp = tmp * a + array_2[x, y] * b\n",
    "            result_view[x, y] = tmp + c\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "import numpy as np \n",
    "\n",
    "DTYPE = np.intc\n",
    "\n",
    "cdef class SomeMemoryNp:\n",
    "    cdef int[:] data\n",
    "    cdef list a, b\n",
    "    cdef int[:, :] c, d\n",
    "    \n",
    "    def __cinit__(self, double number):\n",
    "        self.data = np.zeros(int(number), dtype=DTYPE)\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "\n",
    "import numpy as np \n",
    "cimport numpy as np \n",
    "\n",
    "cdef int categorical(int k, np.ndarray[np.float64_t, ndim=1] p):\n",
    "    return np.random.choice(range(k), p=p)\n",
    "\n",
    "cdef int bernoilli(float p):\n",
    "    return np.random.binomial(1, p)\n",
    "\n",
    "def test_cat():\n",
    "    return categorical(5, np.array([.2, .2, .2, .2, .2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.zeros>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cdef int t() nogil:\n",
    "    cdef int[2] p\n",
    "    p[0] = 0\n",
    "    p[1] = 1\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "\n",
    "cdef int[2] p\n",
    "p[0] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_3ff31f45dd189ed87b1968789ecc3794.pyx:16:26: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_3ff31f45dd189ed87b1968789ecc3794.pyx:19:18: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_3ff31f45dd189ed87b1968789ecc3794.pyx:21:16: Use boundscheck(False) for faster access\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "from libc.stdlib cimport rand, RAND_MAX\n",
    "\n",
    "cdef int random_int(int max_num) nogil:\n",
    "    return <int>(rand() / (RAND_MAX + 1) * max_num)\n",
    "\n",
    "cdef float random_float(int max_num) nogil:\n",
    "    return (rand() / (RAND_MAX + 1) * max_num)\n",
    "\n",
    "cdef int categorical(int k, int[:] p) nogil:\n",
    "    cdef int sum_of_weight = 0;\n",
    "    cdef int i\n",
    "    for i in range(k):\n",
    "        sum_of_weight += p[i];\n",
    "    cdef int rnd = random_int(sum_of_weight);\n",
    "    for i in range(k):\n",
    "        if rnd < p[i]:\n",
    "            return i;\n",
    "        rnd -= p[i];\n",
    "\n",
    "cdef int bernoilli(float p) nogil:\n",
    "    cdef float r = random_float(1)\n",
    "    if r < p:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def b():\n",
    "    return bernoilli(.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = []\n",
    "for i in range(1000000):\n",
    "    bs.append(b())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    699440\n",
       "0    300560\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(bs).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "from libc.math cimport log, exp \n",
    "def logger():\n",
    "    return exp(log(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_1988d87044608c41de89a8214a29cce4.pyx:12:26: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_1988d87044608c41de89a8214a29cce4.pyx:15:18: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\alexa\\.ipython\\cython\\_cython_magic_1988d87044608c41de89a8214a29cce4.pyx:17:16: Use boundscheck(False) for faster access\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "from libc.stdlib cimport rand, RAND_MAX\n",
    "\n",
    "\n",
    "cdef float random(float max_num) nogil:\n",
    "    return (rand() / (RAND_MAX + 1) * max_num)\n",
    "\n",
    "cdef int categorical(int k, float[:] p) nogil:\n",
    "    cdef float sum_of_weight = 0;\n",
    "    cdef int i\n",
    "    for i in range(k):\n",
    "        sum_of_weight += p[i];\n",
    "    cdef float rnd = random(sum_of_weight);\n",
    "    for i in range(k):\n",
    "        if rnd < p[i]:\n",
    "            return i;\n",
    "        rnd -= p[i];\n",
    "\n",
    "cdef int bernoilli(float p) nogil:\n",
    "    cdef float r = rand() / (RAND_MAX + 1)\n",
    "    if r < p:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cimport numpy as np \n",
    "import numpy as np \n",
    "\n",
    "DTYPE = np.intc\n",
    "\n",
    "cdef int l(int[:] a) nogil:\n",
    "    return len(a)\n",
    "\n",
    "def t():\n",
    "    cdef int[:] a = np.zeros(4, dtype=DTYPE)\n",
    "    return l(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np \n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import glob, re\n",
    "import random\n",
    "from cython.parallel import prange\n",
    "from libc.math cimport log, exp \n",
    "from libc.stdlib cimport rand, RAND_MAX\n",
    "import cython \n",
    "from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free\n",
    "\n",
    "DTYPE = np.intc\n",
    "\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)   # Deactivate negative indexing.\n",
    "cdef float random_double(double  max_num) nogil:\n",
    "    return (rand() / (RAND_MAX + 1) * max_num)\n",
    "\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)   # Deactivate negative indexing.\n",
    "cdef int categorical(int k, double[:] p) nogil:\n",
    "    cdef double sum_of_weight = 0;\n",
    "    cdef int i\n",
    "    for i in range(k):\n",
    "        sum_of_weight += p[i];\n",
    "    cdef double rnd = random_double(sum_of_weight);\n",
    "    for i in range(k):\n",
    "        if rnd < p[i]:\n",
    "            return i;\n",
    "        rnd -= p[i];\n",
    "\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)   # Deactivate negative indexing.\n",
    "cdef int bernoilli(float p) nogil:\n",
    "    cdef float r = rand() / (RAND_MAX + 1)\n",
    "    if r < p:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "cdef class BOW_Paragraph_GibbsSampler():\n",
    "    cdef int ***docs \n",
    "    cdef int[:] num_pars_per_doc\n",
    "    cdef int **num_words_per_par_per_doc\n",
    "\n",
    "    cdef Py_ssize_t n_docs, n_graphs, n_vocab, num_partypes, num_topics, max_graphs_per_doc\n",
    "    cdef float H_T, H_P, gamma, alpha, beta\n",
    "    \n",
    "    cdef int[:] partype_counts, doc__wordtopic_counts, partype__wordtopic_counts, wordtopic__word_counts\n",
    "    cdef int[:, :] doc_by_wordtopic__wordtopic_counts, partype_by_wordtopic__wordtopic_counts, vocab_by_wordtopic__word_counts\n",
    "    cdef int[:, :] pardoc_to_type, old_pardoc_to_type\n",
    "    cdef int*** word_to_topic\n",
    "    cdef int*** switching_variable\n",
    "    cdef int*** old_switching_variable\n",
    "\n",
    "    def __cinit__(\n",
    "        self, list docs, list vocab, Py_ssize_t num_partypes=10, Py_ssize_t num_topics=25, \n",
    "        float H_P_prior=1, float H_T_prior=1, float gamma=.7, float alpha=1., float beta=1.\n",
    "    ):\n",
    "        # copy word-level and paragraph-level data\n",
    "        self.docs = <int***>PyMem_Malloc(len(docs) * sizeof(int**))\n",
    "        self.word_to_topic = <int***>PyMem_Malloc(len(docs) * sizeof(int**))\n",
    "        self.switching_variable = <int***>PyMem_Malloc(len(docs) * sizeof(int**))\n",
    "        self.old_switching_variable = <int***>PyMem_Malloc(len(docs) * sizeof(int**))\n",
    "        self.num_words_per_par_per_doc = <int**>PyMem_Malloc(len(docs) * sizeof(int**))\n",
    "        cdef int i, j, k\n",
    "        for i in range(len(docs)):\n",
    "            self.docs[i] = <int**> PyMem_Malloc(len(docs[i]) * sizeof(int*))\n",
    "            self.word_to_topic[i] = <int**> PyMem_Malloc(len(docs[i]) * sizeof(int*))\n",
    "            self.switching_variable[i] = <int**> PyMem_Malloc(len(docs[i]) * sizeof(int*))\n",
    "            self.old_switching_variable[i] = <int**> PyMem_Malloc(len(docs[i]) * sizeof(int*))\n",
    "            self.num_words_per_par_per_doc[i] = <int*> PyMem_Malloc(len(docs[i]) * sizeof(int))\n",
    "            for j in range(len(docs[i])):\n",
    "                self.docs[i][j] = <int*> PyMem_Malloc(len(docs[i][j]) * sizeof(int))\n",
    "                self.word_to_topic[i][j] = <int*> PyMem_Malloc(len(docs[i][j]) * sizeof(int))\n",
    "                self.switching_variable[i][j] = <int*> PyMem_Malloc(len(docs[i][j]) * sizeof(int))\n",
    "                self.old_switching_variable[i][j] = <int*> PyMem_Malloc(len(docs[i][j]) * sizeof(int))\n",
    "                self.num_words_per_par_per_doc[i][j] = len(docs[i][j])\n",
    "                for k in range(len(docs[i][j])):\n",
    "                    self.docs[i][j][k] = docs[i][j][k]\n",
    "            \n",
    "        self.num_pars_per_doc = np.array(list(map(lambda x: len(x), docs)), dtype=DTYPE)\n",
    "        self.n_docs = len(docs)\n",
    "        self.n_graphs = sum(list(map(lambda x: len(x), docs)))\n",
    "        self.max_graphs_per_doc = max(list(map(lambda x: len(x), docs)))\n",
    "        self.n_vocab = len(vocab)\n",
    "\n",
    "        # hyperparameters\n",
    "        self.num_partypes = num_partypes\n",
    "        self.num_topics = num_topics\n",
    "\n",
    "        # priors\n",
    "        self.H_T = H_T_prior\n",
    "        self.H_P = H_P_prior\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        # counts \n",
    "        ## doc-type probability\n",
    "        #### I(doc d has type t)\n",
    "        #### count_t_d\n",
    "        self.partype_counts = np.zeros(self.num_partypes, dtype=DTYPE)\n",
    "        self.pardoc_to_type = np.zeros((self.n_docs, self.max_graphs_per_doc), dtype=DTYPE)\n",
    "        self.old_pardoc_to_type = np.zeros((self.n_docs, self.max_graphs_per_doc), dtype=DTYPE)\n",
    "\n",
    "        ## background word-topic probabilities\n",
    "        #### I(doc d has type t, word w has topic k)\n",
    "        #### count_k_d_t_w\n",
    "        self.doc__wordtopic_counts = np.zeros(self.n_docs, dtype=DTYPE)\n",
    "        self.doc_by_wordtopic__wordtopic_counts = np.zeros((self.n_docs, self.num_topics), dtype=DTYPE)\n",
    "\n",
    "        ## paragraph word-topic probabilities\n",
    "        #### I(source S_d in doc d has type s, word w has topic k)\n",
    "        #### count_k_d_s_Sd_w\n",
    "        self.partype__wordtopic_counts = np.zeros(self.num_partypes, dtype=DTYPE)\n",
    "        self.partype_by_wordtopic__wordtopic_counts = np.zeros((self.num_partypes, self.num_topics), dtype=DTYPE)\n",
    "\n",
    "        ## word probabilities\n",
    "        self.vocab_by_wordtopic__word_counts = np.zeros((self.n_vocab, self.num_topics), dtype=DTYPE)\n",
    "        self.wordtopic__word_counts = np.zeros(self.num_topics, dtype=DTYPE)\n",
    "\n",
    "    def initialize(self):\n",
    "        ## probability vectors\n",
    "        cdef double[:] partype_prob_vec = np.ones(self.num_partypes, dtype=np.float64)\n",
    "        cdef double[:] z_prob_vec = np.ones(self.num_topics, dtype=np.float64)\n",
    "\n",
    "        cdef doc_id, par_id, word\n",
    "        cdef int** doc\n",
    "        cdef int* par\n",
    "        ## iterate through documents\n",
    "        for doc_id in range(self.n_docs):\n",
    "            doc = self.docs[doc_id]\n",
    "            for par_id in range(self.num_pars_per_doc[doc_id]):\n",
    "                par = doc[par_id]\n",
    "                partype = categorical(self.num_partypes, p=partype_prob_vec)\n",
    "                self.partype_counts[partype] += 1\n",
    "                self.pardoc_to_type[doc_id, par_id] = partype\n",
    "                self.old_pardoc_to_type[doc_id, par_id] = partype\n",
    "\n",
    "                for word_id in range(self.num_words_per_par_per_doc[doc_id][par_id]):\n",
    "                    word = par[word_id]\n",
    "                    s = bernoilli(self.gamma)\n",
    "                    self.switching_variable[doc_id][par_id][word_id] = s\n",
    "                    self.old_switching_variable[doc_id][par_id][word_id] = s\n",
    "\n",
    "                    word_topic = categorical(self.num_topics, p=z_prob_vec)\n",
    "                    if s == 0:\n",
    "                        ## set paragraph word-topics counts\n",
    "                        self.partype_by_wordtopic__wordtopic_counts[partype, word_topic] += 1\n",
    "                        self.partype__wordtopic_counts[partype] += 1\n",
    "                        self.vocab_by_wordtopic__word_counts[word, word_topic] += 1\n",
    "                        self.wordtopic__word_counts[word_topic] += 1\n",
    "\n",
    "                    else:\n",
    "                        ## set document word-topic counts\n",
    "                        self.doc_by_wordtopic__wordtopic_counts[doc_id, word_topic] += 1\n",
    "                        self.doc__wordtopic_counts[doc_id] += 1\n",
    "                        self.vocab_by_wordtopic__word_counts[word, word_topic] += 1\n",
    "                        self.wordtopic__word_counts[word_topic] += 1\n",
    "\n",
    "                    ## cache\n",
    "                    self.word_to_topic[doc_id][par_id][word_id] = word_topic\n",
    "\n",
    "\n",
    "    def __dealloc__(self):\n",
    "        PyMem_Free(self.docs)  # no-op if self.data is NULL\n",
    "        PyMem_Free(self.num_words_per_par_per_doc)\n",
    "        PyMem_Free(self.switching_variable)\n",
    "        PyMem_Free(self.old_switching_variable)\n",
    "        PyMem_Free(self.word_to_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = BOW_Paragraph_GibbsSampler(docs=docs[:100], vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def test(arr):\n",
    "    cdef double[:] output_arr = arr\n",
    "    return output_arr\n",
    "\n",
    "cdef void test2():\n",
    "    a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MemoryView of 'ndarray' at 0x1bde237ba38>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test(np.array([1,2,3], dtype=np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free\n",
    "def test():\n",
    "    \n",
    "    cdef int **array = <int**>PyMem_Malloc(10 * sizeof(int*))\n",
    "    array[0] = <int*> PyMem_Malloc(10*sizeof(int))\n",
    "    array[1] = <int*> PyMem_Malloc(20*sizeof(int))\n",
    "    \n",
    "    array[0][0] = 5\n",
    "    array[1][1000] = 10\n",
    "    return (array[0][0], array[1][10])\n",
    "#     PyMem_Free(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "cdef t():\n",
    "    cdef double[:] a = np.zeros(10)\n",
    "    return a\n",
    "    \n",
    "def t2():\n",
    "    return np.asarray(t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
